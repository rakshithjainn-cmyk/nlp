## requirements.txt
```text
opencv-python
numpy
pandas
tensorflow
keras
streamlit
nltk
matplotlib
googletrans==4.0.0-rc1
scikit-learn
## src/data\_loader.py

```python
import cv2
import os
import numpy as np
from sklearn.model_selection import train_test_split

def load_data(data_dir, img_size=(64,64)):
    X, y = [], []
    labels = os.listdir(data_dir)
    label_map = {label: idx for idx, label in enumerate(labels)}
    
    for label in labels:
        path = os.path.join(data_dir, label)
        for img_name in os.listdir(path):
            img_path = os.path.join(path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, img_size)
            X.append(img)
            y.append(label_map[label])
    
    X = np.array(X).reshape(-1, img_size[0], img_size[1], 1) / 255.0
    y = np.array(y)
    return train_test_split(X, y, test_size=0.2, random_state=42), label_map
## src/model.py

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed

def create_cnn_lstm(input_shape, num_classes):
    model = Sequential([
        TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=input_shape),
        TimeDistributed(MaxPooling2D(2, 2)),
        TimeDistributed(Conv2D(64, (3, 3), activation='relu')),
        TimeDistributed(MaxPooling2D(2, 2)),
        TimeDistributed(Flatten()),
        LSTM(128, return_sequences=False),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model
## src/train.py

```python
import numpy as np
from src.data_loader import load_data
from src.model import create_cnn_lstm
import joblib

def train(data_dir='data/signs'):
    (X_train, X_test, y_train, y_test), label_map = load_data(data_dir)
    model = create_cnn_lstm((None, 64, 64, 1), num_classes=len(label_map))
    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))
    model.save('models/sign_model.h5')
    joblib.dump(label_map, 'models/label_map.pkl')

if __name__ == '__main__':
    train()
```

---

## src/predict.py

```python
import numpy as np
import cv2
import joblib
from tensorflow.keras.models import load_model

model = load_model('models/sign_model.h5')
label_map = joblib.load('models/label_map.pkl')
inv_label_map = {v: k for k, v in label_map.items()}

def predict_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (64,64))
    img = img.reshape(1,1,64,64,1) / 255.0
    pred = model.predict(img)
    label = inv_label_map[np.argmax(pred)]
    return label

## app/translate.py

```python
from googletrans import Translator

translator = Translator()

def translate_text(text, dest='fr'):
    return translator.translate(text, dest=dest).text
## app/ui.py

```python
import streamlit as st
from src.predict import predict_image
from app.translate import translate_text

st.title("Indian Sign Language Recognition & Translation")

uploaded_file = st.file_uploader("Upload a sign image", type=["jpg", "png"])
language = st.selectbox("Translate to", ["en", "fr", "es", "hi"])

if uploaded_file is not None:
    with open("temp.png", "wb") as f:
        f.write(uploaded_file.getbuffer())
    prediction = predict_image("temp.png")
    translation = translate_text(prediction, dest=language)
    st.image("temp.png")
    st.write(f"**Detected Sign:** {prediction}")
    st.write(f"**Translation:** {translation}")
```
## .gitignore
__pycache__/
*.pkl
*.h5
models/
.env
